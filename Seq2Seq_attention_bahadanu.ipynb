{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 29000\n",
      "Number of validation examples: 1014\n",
      "Number of testing examples: 1000\n",
      "{'src': ['zwei', 'junge', 'weiße', 'männer', 'sind', 'im', 'freien', 'in', 'der', 'nähe', 'vieler', 'büsche', '.'], 'trg': ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']}\n",
      "Unique tokens in source (de) vocabulary: 7853\n",
      "Unique tokens in target (en) vocabulary: 5893\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import os, sys\n",
    "\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings (tokens) and reverses it\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings (tokens)\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "SRC = Field(tokenize=tokenize_de, init_token='<sos>', eos_token='<eos>', lower=True)\n",
    "TRG = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>', lower=True)\n",
    "\n",
    "train_data, valid_data, test_data = Multi30k.splits(exts=('.de', '.en'), fields=(SRC, TRG))\n",
    "\n",
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")\n",
    "\n",
    "\n",
    "print(vars(train_data.examples[0]))\n",
    "\n",
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)\n",
    "\n",
    "print(f\"Unique tokens in source (de) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), batch_size=BATCH_SIZE, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True)\n",
    "        \n",
    "        self.linear = nn.Linear(enc_hid_dim, dec_hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        # input dim => (src_sent_len, batch_size)\n",
    "        embed = self.dropout(self.embedding(input))\n",
    "        \n",
    "        # embed dim => (src_sent_len, batch_size, emb_dim)\n",
    "        outputs, hidden = self.rnn(embed)\n",
    "        \n",
    "        # outputs dim => (src_sent_len, batch size, enc_hid_dim * num directions)\n",
    "        # hidden dim => (number of layers * number of directions, batch size, enc_hid_dim)\n",
    "        \n",
    "        hidden = torch.tanh(self.linear(hidden[-1, :, :]))\n",
    "        \n",
    "        # hidden dim => (batch size, dec_hid_dim)\n",
    "        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        \n",
    "        self.attn = nn.Linear(enc_hid_dim * 2 + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Parameter(torch.randn(dec_hid_dim))\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \n",
    "        # hidden should be => (number of layers * number of directions, batch size, dec_hid_dim))\n",
    "        # but the author did a squeeze operation in the decoder before returning the last hidden state\n",
    "        # so hidden dimension becomes => (batch size, dec_hid_dim)\n",
    "        # another reason to do this would be keep hidden dim similar in both encoder and decoder\n",
    "        \n",
    "        # hidden dimension becomes => (batch size, dec_hid_dim)\n",
    "        # encoder_outputs dimension => (src_sent_len, batch size, enc_hid_dim * num directions)\n",
    "        \n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len,1)\n",
    "        # hidden new dim = > (batch_size, src_len, dec_hid_dim) \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        # encoder_outputs new dim = > (batch_size, src_len, enc_hid_dim * 2) \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2)))\n",
    "        \n",
    "        # attn dim = > (batch_size, src_len, dec_hid_dim)\n",
    "        energy = energy.permute(0, 2, 1)\n",
    "        \n",
    "        # we want to compute energy whose dimension is => (batch size, dec_hid_dim, source sent len)\n",
    "        \n",
    "        # v dim should be => (batch_size, 1, dec-hid_dim)\n",
    "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
    "        \n",
    "        # attention dim (batch_size, 1, src_len)\n",
    "        # torch.bmm(batch1, batch2, out=None) → Tensor\n",
    "        # If batch1 is a (b×n×m) tensor, batch2 is a (b×m×p) tensor, out will be a (b×n×p) tensor\n",
    "        attention = torch.bmm(v, energy).squeeze(1)\n",
    "        \n",
    "        # attention dim (batch_size, src_len)\n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.dropout = dropout\n",
    "        self.attention = attention\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(enc_hid_dim * 2 + emb_dim, dec_hid_dim)\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2 + emb_dim + dec_hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, encoder_outputs, hidden):\n",
    "        \n",
    "        # input dim => [batch_size]\n",
    "        # encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
    "#         print(\"decoder input 1\")\n",
    "#         print(input)\n",
    "        input = input.unsqueeze(0)\n",
    "        # input dim => [1, batch_size]\n",
    "#         print(\"decoder input 2\")\n",
    "#         print(input)\n",
    "\n",
    "\n",
    "        embed = self.dropout(self.embedding(input))\n",
    "#         print(\"decoder input 3\")\n",
    "        \n",
    "\n",
    "        # embed dimension => (1, batch_size, emb_dim)\n",
    "        \n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "        # a dim => (batch_size, src_len)\n",
    "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
    "        a = a.unsqueeze(1)\n",
    "        # a dim => (batch_size, 1, src_len)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        # a dim => (batch_size, 1, src_len)\n",
    "        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        # weighted dim => (batch_size, 1, enc_hid_dim * 2)\n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        # weighted dim => (1, batch_size, enc_hid_dim * 2)\n",
    "\n",
    "        rnn_input = torch.cat((weighted, embed), dim=2)\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        \n",
    "        # outputs dim => (src_sent_len, batch size, enc_hid_dim * num directions)\n",
    "        # hidden dim => (number of layers * number of directions, batch size, enc_hid_dim)\n",
    "        \n",
    "        # here src_sent_len = number of layers = number of directions = 1 for decoder only\n",
    "        # sp basically\n",
    "        # outputs dim => (1, batch size, enc_hid_dim * num directions)\n",
    "        # hidden dim => (1, batch size, enc_hid_dim)\n",
    "        \n",
    "        \n",
    "        prediction = self.fc(torch.cat((output.squeeze(0), weighted.squeeze(0), embed.squeeze(0)), dim=1))\n",
    "        return prediction, hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        \n",
    "        #src = [sent len, batch size]\n",
    "        #trg = [sent len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        max_len = trg.shape[0]\n",
    "#         print(\"trg shape\", trg.shape)\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "#         print(\"batch size \", batch_size)\n",
    "#         print(\"max len \", max_len)\n",
    "#         print(\"trg vocab size \", trg_vocab_size)\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "#         print(\"shape of outputs\")\n",
    "#         print(outputs.shape)\n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        output = trg[0,:]\n",
    "#         print(\"first input\")\n",
    "#         print(output)\n",
    "        for t in range(1, max_len):\n",
    "#             print(\"in LOOP\")\n",
    "            output, hidden = self.decoder(output, encoder_outputs, hidden)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "#             print(\"output in loop\")\n",
    "#             print(output)\n",
    "#             print(output.max(1))\n",
    "            top1 = output.max(1)[1] # index of the max value\n",
    "            output = (trg[t] if teacher_force else top1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "pad_idx = TRG.vocab.stoi['<pad>']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        print(\"train iterator \", i)\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        print(\"src\")\n",
    "        print(src)\n",
    "        print(\"target\")\n",
    "        print(trg)\n",
    "        exit()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "#         print(\"output after seq2seq\")\n",
    "#         print(output)\n",
    "#         print(output.shape)\n",
    "        #trg = [sent len, batch size]\n",
    "        #output = [sent len, batch size, output dim]\n",
    "        \n",
    "        #reshape to:\n",
    "        #trg = [(sent len - 1) * batch size]\n",
    "        #output = [(sent len - 1) * batch size, output dim]\n",
    "        x = output[1:].view(-1, output.shape[2])\n",
    "        y = trg[1:].view(-1)\n",
    "#         print(\"X \", x.shape)\n",
    "#         print(x[0])\n",
    "#         print(\"Y \", y.shape)\n",
    "#         print(y)\n",
    "        loss = criterion(output[1:].view(-1, output.shape[2]), trg[1:].view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_final(t):\n",
    "    sentences = []\n",
    "    for i in range(len(t[0])):\n",
    "        tensor_out = t[:, i]\n",
    "        tensor_out = list(tensor_out.numpy())\n",
    "        sentence = []\n",
    "        for j in tensor_out:\n",
    "            if TRG.vocab.itos[j] == '<pad>':\n",
    "                break\n",
    "            if TRG.vocab.itos[j] == '<eos>':\n",
    "                sentence.append(TRG.vocab.itos[j])\n",
    "                break\n",
    "            sentence.append(TRG.vocab.itos[j])\n",
    "        sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def process_output(output):\n",
    "    y = []\n",
    "    for elem in output:\n",
    "        x = []\n",
    "        z = []\n",
    "        for arr in elem:\n",
    "            values, indices = arr.max(0)\n",
    "            x.append(indices.item())\n",
    "            z.append(values.item())\n",
    "#         print(\"printing x\")\n",
    "#         print(x)\n",
    "#         print(\"printing z\")\n",
    "#         print(z)\n",
    "\n",
    "\n",
    "        y.append(x)\n",
    "    final_tensor = torch.tensor(y)\n",
    "    print(\"final tensor \")\n",
    "    print(final_tensor)\n",
    "    return process_final(final_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, testing):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    bleu_score = 0\n",
    "    count_pair = 0\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "            if testing:\n",
    "                output_a = output[1:]\n",
    "                trg_a = trg[1:]\n",
    "\n",
    "                sent_out = process_output(output_a)\n",
    "                sent_trg = process_final(trg_a)\n",
    "                for o, t in zip(sent_out, sent_trg):\n",
    "                    reference = [t]\n",
    "                    candidate = o\n",
    "                    print(\"reference \")\n",
    "                    print(reference)\n",
    "                    print(\"candidate \")\n",
    "                    print(candidate)\n",
    "                    bleu_score += sentence_bleu(reference, candidate)\n",
    "                    count_pair += 1\n",
    "            x = output[1:].view(-1, output.shape[2])\n",
    "            y = trg[1:].view(-1)\n",
    "            loss = criterion(output[1:].view(-1, output.shape[2]), trg[1:].view(-1))\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        if testing:\n",
    "            print(\"count pair \", count_pair)\n",
    "            print(\"bleu score \")\n",
    "\n",
    "\n",
    "            print(bleu_score / count_pair)\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "train iterator  0\n",
      "src\n",
      "tensor([[   2],\n",
      "        [  45],\n",
      "        [   7],\n",
      "        [1384],\n",
      "        [   9],\n",
      "        [   0],\n",
      "        [  97],\n",
      "        [ 185],\n",
      "        [  23],\n",
      "        [  12],\n",
      "        [   6],\n",
      "        [ 338],\n",
      "        [  47],\n",
      "        [   6],\n",
      "        [5738],\n",
      "        [   4],\n",
      "        [   3]])\n",
      "target\n",
      "tensor([[   2],\n",
      "        [  50],\n",
      "        [   6],\n",
      "        [ 263],\n",
      "        [ 990],\n",
      "        [ 219],\n",
      "        [ 688],\n",
      "        [   6],\n",
      "        [   4],\n",
      "        [ 275],\n",
      "        [  71],\n",
      "        [  18],\n",
      "        [   4],\n",
      "        [1075],\n",
      "        [ 100],\n",
      "        [   5],\n",
      "        [   3]])\n",
      "train iterator  1\n",
      "src\n",
      "tensor([[   2],\n",
      "        [   5],\n",
      "        [  49],\n",
      "        [1872],\n",
      "        [ 326],\n",
      "        [   7],\n",
      "        [  15],\n",
      "        [  90],\n",
      "        [   9],\n",
      "        [1540],\n",
      "        [  58],\n",
      "        [ 221],\n",
      "        [2894],\n",
      "        [   4],\n",
      "        [   3]])\n",
      "target\n",
      "tensor([[   2],\n",
      "        [   4],\n",
      "        [ 348],\n",
      "        [1142],\n",
      "        [   6],\n",
      "        [ 445],\n",
      "        [  49],\n",
      "        [  74],\n",
      "        [3323],\n",
      "        [   5],\n",
      "        [   3]])\n",
      "train iterator  2\n",
      "src\n",
      "tensor([[   2],\n",
      "        [  43],\n",
      "        [3897],\n",
      "        [  30],\n",
      "        [   9],\n",
      "        [  17],\n",
      "        [  21],\n",
      "        [   6],\n",
      "        [ 938],\n",
      "        [2220],\n",
      "        [   4],\n",
      "        [   3]])\n",
      "target\n",
      "tensor([[   2],\n",
      "        [  48],\n",
      "        [  79],\n",
      "        [  30],\n",
      "        [1202],\n",
      "        [   6],\n",
      "        [   4],\n",
      "        [ 644],\n",
      "        [   5],\n",
      "        [   3]])\n",
      "train iterator  3\n",
      "src\n",
      "tensor([[  2],\n",
      "        [  8],\n",
      "        [655],\n",
      "        [196],\n",
      "        [920],\n",
      "        [  9],\n",
      "        [ 17],\n",
      "        [ 59],\n",
      "        [ 14],\n",
      "        [619],\n",
      "        [ 17],\n",
      "        [ 34],\n",
      "        [ 72],\n",
      "        [ 60],\n",
      "        [  4],\n",
      "        [  3]])\n",
      "target\n",
      "tensor([[  2],\n",
      "        [  4],\n",
      "        [ 38],\n",
      "        [ 12],\n",
      "        [ 19],\n",
      "        [ 15],\n",
      "        [ 73],\n",
      "        [  7],\n",
      "        [668],\n",
      "        [ 41],\n",
      "        [ 40],\n",
      "        [  7],\n",
      "        [ 39],\n",
      "        [ 15],\n",
      "        [  6],\n",
      "        [  4],\n",
      "        [398],\n",
      "        [  5],\n",
      "        [  3]])\n",
      "train iterator  4\n",
      "src\n",
      "tensor([[  2],\n",
      "        [  5],\n",
      "        [ 13],\n",
      "        [667],\n",
      "        [ 11],\n",
      "        [ 14],\n",
      "        [  0],\n",
      "        [ 17],\n",
      "        [ 34],\n",
      "        [  4],\n",
      "        [  3]])\n",
      "target\n",
      "tensor([[   2],\n",
      "        [   4],\n",
      "        [   9],\n",
      "        [  10],\n",
      "        [ 195],\n",
      "        [   4],\n",
      "        [2562],\n",
      "        [  42],\n",
      "        [1938],\n",
      "        [  18],\n",
      "        [1489],\n",
      "        [   7],\n",
      "        [  39],\n",
      "        [   5],\n",
      "        [   3]])\n",
      "train iterator  5\n",
      "src\n",
      "tensor([[  2],\n",
      "        [  8],\n",
      "        [ 16],\n",
      "        [ 11],\n",
      "        [680],\n",
      "        [160],\n",
      "        [212],\n",
      "        [ 85],\n",
      "        [ 39],\n",
      "        [148],\n",
      "        [  4],\n",
      "        [  3]])\n",
      "target\n",
      "tensor([[  2],\n",
      "        [  4],\n",
      "        [ 14],\n",
      "        [ 22],\n",
      "        [175],\n",
      "        [148],\n",
      "        [436],\n",
      "        [ 54],\n",
      "        [  7],\n",
      "        [342],\n",
      "        [  5],\n",
      "        [  3]])\n",
      "train iterator  6\n",
      "src\n",
      "tensor([[   2],\n",
      "        [   5],\n",
      "        [  26],\n",
      "        [  10],\n",
      "        [ 132],\n",
      "        [2082],\n",
      "        [  57],\n",
      "        [  11],\n",
      "        [2028],\n",
      "        [  10],\n",
      "        [3437],\n",
      "        [   4],\n",
      "        [   3]])\n",
      "target\n",
      "tensor([[   2],\n",
      "        [   4],\n",
      "        [  34],\n",
      "        [  11],\n",
      "        [  27],\n",
      "        [1986],\n",
      "        [  17],\n",
      "        [  37],\n",
      "        [  13],\n",
      "        [ 758],\n",
      "        [  11],\n",
      "        [2877],\n",
      "        [   5],\n",
      "        [   3]])\n",
      "train iterator  7\n",
      "src\n",
      "tensor([[   2],\n",
      "        [   5],\n",
      "        [ 717],\n",
      "        [ 124],\n",
      "        [  11],\n",
      "        [  24],\n",
      "        [  92],\n",
      "        [  21],\n",
      "        [  77],\n",
      "        [1539],\n",
      "        [ 117],\n",
      "        [   4],\n",
      "        [   3]])\n",
      "target\n",
      "tensor([[  2],\n",
      "        [  4],\n",
      "        [192],\n",
      "        [105],\n",
      "        [212],\n",
      "        [232],\n",
      "        [ 27],\n",
      "        [575],\n",
      "        [ 13],\n",
      "        [  7],\n",
      "        [ 68],\n",
      "        [  5],\n",
      "        [  3]])\n",
      "train iterator  8\n",
      "src\n",
      "tensor([[   2],\n",
      "        [ 131],\n",
      "        [ 367],\n",
      "        [   5],\n",
      "        [  49],\n",
      "        [  11],\n",
      "        [ 357],\n",
      "        [1124],\n",
      "        [   7],\n",
      "        [ 197],\n",
      "        [  81],\n",
      "        [   4],\n",
      "        [   3]])\n",
      "target\n",
      "tensor([[  2],\n",
      "        [  4],\n",
      "        [ 55],\n",
      "        [ 10],\n",
      "        [ 57],\n",
      "        [536],\n",
      "        [ 13],\n",
      "        [  4],\n",
      "        [381],\n",
      "        [ 12],\n",
      "        [711],\n",
      "        [  6],\n",
      "        [ 27],\n",
      "        [181],\n",
      "        [  5],\n",
      "        [  3]])\n",
      "train iterator  9\n",
      "src\n",
      "tensor([[   2],\n",
      "        [   5],\n",
      "        [3167],\n",
      "        [  55],\n",
      "        [  91],\n",
      "        [ 594],\n",
      "        [  63],\n",
      "        [   4],\n",
      "        [   3]])\n",
      "target\n",
      "tensor([[   2],\n",
      "        [   4],\n",
      "        [2679],\n",
      "        [   8],\n",
      "        [   4],\n",
      "        [  88],\n",
      "        [  13],\n",
      "        [ 549],\n",
      "        [  47],\n",
      "        [   5],\n",
      "        [   3]])\n",
      "train iterator  10\n",
      "src\n",
      "tensor([[  2],\n",
      "        [  8],\n",
      "        [315],\n",
      "        [ 16],\n",
      "        [  7],\n",
      "        [237],\n",
      "        [250],\n",
      "        [  9],\n",
      "        [ 17],\n",
      "        [134],\n",
      "        [164],\n",
      "        [ 37],\n",
      "        [  4],\n",
      "        [  3]])\n",
      "target\n",
      "tensor([[  2],\n",
      "        [ 21],\n",
      "        [106],\n",
      "        [ 14],\n",
      "        [  6],\n",
      "        [  4],\n",
      "        [ 31],\n",
      "        [317],\n",
      "        [ 45],\n",
      "        [ 44],\n",
      "        [153],\n",
      "        [  5],\n",
      "        [  3]])\n",
      "train iterator  11\n",
      "src\n",
      "tensor([[ 2],\n",
      "        [ 5],\n",
      "        [13],\n",
      "        [29],\n",
      "        [20],\n",
      "        [63],\n",
      "        [ 4],\n",
      "        [ 3]])\n",
      "target\n",
      "tensor([[ 2],\n",
      "        [ 4],\n",
      "        [ 9],\n",
      "        [36],\n",
      "        [ 6],\n",
      "        [ 7],\n",
      "        [47],\n",
      "        [ 5],\n",
      "        [ 3]])\n",
      "train iterator  12\n",
      "src\n",
      "tensor([[  2],\n",
      "        [ 18],\n",
      "        [ 41],\n",
      "        [  7],\n",
      "        [  0],\n",
      "        [ 74],\n",
      "        [  8],\n",
      "        [ 34],\n",
      "        [154],\n",
      "        [  4],\n",
      "        [  3]])\n",
      "target\n",
      "tensor([[  2],\n",
      "        [ 16],\n",
      "        [ 19],\n",
      "        [ 17],\n",
      "        [ 22],\n",
      "        [535],\n",
      "        [567],\n",
      "        [ 11],\n",
      "        [ 41],\n",
      "        [ 40],\n",
      "        [  4],\n",
      "        [ 39],\n",
      "        [  5],\n",
      "        [  3]])\n",
      "train iterator  13\n",
      "src\n",
      "tensor([[   2],\n",
      "        [   5],\n",
      "        [1260],\n",
      "        [ 116],\n",
      "        [  29],\n",
      "        [ 646],\n",
      "        [  27],\n",
      "        [   6],\n",
      "        [ 382],\n",
      "        [ 104],\n",
      "        [   4],\n",
      "        [   3]])\n",
      "target\n",
      "tensor([[  2],\n",
      "        [ 21],\n",
      "        [115],\n",
      "        [154],\n",
      "        [133],\n",
      "        [ 28],\n",
      "        [ 36],\n",
      "        [  6],\n",
      "        [ 43],\n",
      "        [ 12],\n",
      "        [  4],\n",
      "        [289],\n",
      "        [ 77],\n",
      "        [  5],\n",
      "        [  3]])\n",
      "train iterator  14\n",
      "src\n",
      "tensor([[  2],\n",
      "        [  5],\n",
      "        [ 13],\n",
      "        [ 10],\n",
      "        [  8],\n",
      "        [ 16],\n",
      "        [  7],\n",
      "        [  6],\n",
      "        [ 78],\n",
      "        [ 50],\n",
      "        [128],\n",
      "        [262],\n",
      "        [  4],\n",
      "        [  3]])\n",
      "target\n",
      "tensor([[  2],\n",
      "        [  4],\n",
      "        [  9],\n",
      "        [ 11],\n",
      "        [  4],\n",
      "        [ 14],\n",
      "        [  6],\n",
      "        [  4],\n",
      "        [289],\n",
      "        [ 31],\n",
      "        [117],\n",
      "        [239],\n",
      "        [  5],\n",
      "        [  3]])\n",
      "train iterator  15\n",
      "src\n",
      "tensor([[   2],\n",
      "        [   5],\n",
      "        [  96],\n",
      "        [  13],\n",
      "        [  60],\n",
      "        [3235],\n",
      "        [  27],\n",
      "        [ 426],\n",
      "        [ 294],\n",
      "        [  17],\n",
      "        [  34],\n",
      "        [ 378],\n",
      "        [   4],\n",
      "        [   3]])\n",
      "target\n",
      "tensor([[   2],\n",
      "        [   4],\n",
      "        [  24],\n",
      "        [   9],\n",
      "        [ 125],\n",
      "        [1991],\n",
      "        [  40],\n",
      "        [   7],\n",
      "        [  39],\n",
      "        [   6],\n",
      "        [  43],\n",
      "        [  12],\n",
      "        [  74],\n",
      "        [ 250],\n",
      "        [   5],\n",
      "        [   3]])\n",
      "train iterator  16\n",
      "src\n",
      "tensor([[  2],\n",
      "        [  5],\n",
      "        [435],\n",
      "        [359],\n",
      "        [ 19],\n",
      "        [ 92],\n",
      "        [  4],\n",
      "        [  3]])\n",
      "target\n",
      "tensor([[   2],\n",
      "        [   4],\n",
      "        [ 188],\n",
      "        [ 105],\n",
      "        [1233],\n",
      "        [   4],\n",
      "        [  68],\n",
      "        [   5],\n",
      "        [   3]])\n",
      "train iterator  17\n",
      "src\n",
      "tensor([[  2],\n",
      "        [ 17],\n",
      "        [ 16],\n",
      "        [ 11],\n",
      "        [ 33],\n",
      "        [313],\n",
      "        [198],\n",
      "        [ 93],\n",
      "        [125],\n",
      "        [ 81],\n",
      "        [ 12],\n",
      "        [  5],\n",
      "        [388],\n",
      "        [211],\n",
      "        [975],\n",
      "        [  4],\n",
      "        [  3]])\n",
      "target\n",
      "tensor([[   2],\n",
      "        [   7],\n",
      "        [  50],\n",
      "        [  13],\n",
      "        [ 148],\n",
      "        [ 136],\n",
      "        [  44],\n",
      "        [ 139],\n",
      "        [1923],\n",
      "        [   8],\n",
      "        [   4],\n",
      "        [  25],\n",
      "        [ 138],\n",
      "        [   5],\n",
      "        [   3]])\n",
      "train iterator  18\n",
      "src\n",
      "tensor([[  2],\n",
      "        [  8],\n",
      "        [926],\n",
      "        [ 61],\n",
      "        [  8],\n",
      "        [ 89],\n",
      "        [ 10],\n",
      "        [ 37],\n",
      "        [  5],\n",
      "        [929],\n",
      "        [424],\n",
      "        [  4],\n",
      "        [  3]])\n",
      "target\n",
      "tensor([[  2],\n",
      "        [ 21],\n",
      "        [106],\n",
      "        [ 14],\n",
      "        [ 22],\n",
      "        [  4],\n",
      "        [ 81],\n",
      "        [ 11],\n",
      "        [ 45],\n",
      "        [  4],\n",
      "        [315],\n",
      "        [ 12],\n",
      "        [311],\n",
      "        [  5],\n",
      "        [  3]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train iterator  19\n",
      "src\n",
      "tensor([[   2],\n",
      "        [   8],\n",
      "        [  16],\n",
      "        [  27],\n",
      "        [   6],\n",
      "        [ 275],\n",
      "        [  11],\n",
      "        [  15],\n",
      "        [ 514],\n",
      "        [ 208],\n",
      "        [4212],\n",
      "        [5196],\n",
      "        [   0],\n",
      "        [ 233],\n",
      "        [  37],\n",
      "        [   8],\n",
      "        [ 529],\n",
      "        [ 375],\n",
      "        [   4],\n",
      "        [   3]])\n",
      "target\n",
      "tensor([[   2],\n",
      "        [   4],\n",
      "        [  14],\n",
      "        [  45],\n",
      "        [   4],\n",
      "        [  62],\n",
      "        [ 265],\n",
      "        [   6],\n",
      "        [  43],\n",
      "        [  12],\n",
      "        [   4],\n",
      "        [ 160],\n",
      "        [3259],\n",
      "        [  18],\n",
      "        [   0],\n",
      "        [ 160],\n",
      "        [ 206],\n",
      "        [   5],\n",
      "        [   3]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4b2d49b819a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-286d3a05b96e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "SAVE_DIR = 'models'\n",
    "MODEL_SAVE_PATH = os.path.join(SAVE_DIR, 'seq2seq_attention_bahadanu.pt')\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "if not os.path.isdir(f'{SAVE_DIR}'):\n",
    "    os.makedirs(f'{SAVE_DIR}')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(\"epoch \", epoch)\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion, False)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    \n",
    "    print(f'| Epoch: {epoch+1:03} | Train Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f} | Val. Loss: {valid_loss:.3f} | Val. PPL: {math.exp(valid_loss):7.3f} |')\n",
    "    print(f'| Epoch: {epoch+1:03} | Train Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}  |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion, True)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
